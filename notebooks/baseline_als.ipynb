{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f59dad1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lenghanz/group-project-f25-shrekommender-system/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n",
      "/home/lenghanz/group-project-f25-shrekommender-system\n"
     ]
    }
   ],
   "source": [
    "# ALS Baseline Recommender System\n",
    "# Training, evaluation, and inference with cold start handling\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "from scipy.sparse import load_npz, csr_matrix\n",
    "import implicit\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully\")\n",
    "\n",
    "import os\n",
    "os.chdir(\"..\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "943265a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loading Data ===\n",
      "Training matrix shape: (25262, 11557)\n",
      "Training matrix sparsity: 99.9909%\n",
      "Users in training: 25,262\n",
      "Movies in training: 11,557\n",
      "Split strategy: temporal split (last 20% of time)\n",
      "Training interactions: 1,588,619\n",
      "Validation interactions: 380,483\n",
      "âœ“ Data loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Load the processed data\n",
    "print(\"=== Loading Data ===\")\n",
    "\n",
    "# Load the training matrix\n",
    "train_matrix = load_npz('data/processed/train_matrix.npz')\n",
    "print(f\"Training matrix shape: {train_matrix.shape}\")\n",
    "print(f\"Training matrix sparsity: {100 * (1 - train_matrix.nnz / (train_matrix.shape[0] * train_matrix.shape[1])):.4f}%\")\n",
    "\n",
    "# Load mappings\n",
    "with open('data/processed/user_mappings.pkl', 'rb') as f:\n",
    "    user_mappings = pickle.load(f)\n",
    "    \n",
    "with open('data/processed/movie_mappings.pkl', 'rb') as f:\n",
    "    movie_mappings = pickle.load(f)\n",
    "    \n",
    "# Load split metadata\n",
    "with open('data/processed/split_metadata.pkl', 'rb') as f:\n",
    "    split_metadata = pickle.load(f)\n",
    "\n",
    "print(f\"Users in training: {len(user_mappings['user_to_idx']):,}\")\n",
    "print(f\"Movies in training: {len(movie_mappings['movie_to_idx']):,}\")\n",
    "print(f\"Split strategy: {split_metadata['split_strategy']}\")  # Fixed key name\n",
    "print(f\"Training interactions: {split_metadata['train_interactions']:,}\")\n",
    "print(f\"Validation interactions: {split_metadata['val_interactions']:,}\")\n",
    "print(\"âœ“ Data loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc45ccb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training ALS Model ===\n",
      "Model parameters:\n",
      "- Factors: 64\n",
      "- Iterations: 20\n",
      "- Regularization: 0.01\n",
      "- Alpha: 40\n",
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:03<00:00,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Model training completed!\n",
      "\n",
      "Most popular movies (by interaction count):\n",
      " 1. the+shawshank+redemption+1994 (interactions: 10417)\n",
      " 2. inception+2010 (interactions: 9366)\n",
      " 3. star+wars+1977 (interactions: 7334)\n",
      " 4. interstellar+2014 (interactions: 5917)\n",
      " 5. the+matrix+1999 (interactions: 5840)\n",
      " 6. spirited+away+2001 (interactions: 5455)\n",
      " 7. raiders+of+the+lost+ark+1981 (interactions: 5112)\n",
      " 8. blade+runner+1982 (interactions: 5070)\n",
      " 9. harry+potter+and+the+deathly+hallows+part+2+2011 (interactions: 4882)\n",
      "10. the+lord+of+the+rings+the+fellowship+of+the+ring+2001 (interactions: 4779)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train ALS model\n",
    "print(\"=== Training ALS Model ===\")\n",
    "\n",
    "# Model hyperparameters\n",
    "factors = 64\n",
    "iterations = 20\n",
    "regularization = 0.01\n",
    "alpha = 40\n",
    "\n",
    "print(\"Model parameters:\")\n",
    "print(f\"- Factors: {factors}\")\n",
    "print(f\"- Iterations: {iterations}\")\n",
    "print(f\"- Regularization: {regularization}\")\n",
    "print(f\"- Alpha: {alpha}\")\n",
    "\n",
    "# Initialize and train the model\n",
    "model = implicit.als.AlternatingLeastSquares(\n",
    "    factors=factors,\n",
    "    iterations=iterations,\n",
    "    regularization=regularization,\n",
    "    alpha=alpha,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nStarting training...\")\n",
    "# Train on the user-item matrix directly (NOT transposed)\n",
    "# The implicit library expects user-item format for ALS\n",
    "model.fit(train_matrix * alpha)\n",
    "print(\"âœ“ Model training completed!\")\n",
    "\n",
    "# Get most popular movies for cold start handling\n",
    "movie_popularity = np.array(train_matrix.sum(axis=0)).flatten()\n",
    "popular_movie_indices = np.argsort(-movie_popularity)[:10]\n",
    "\n",
    "print(\"\\nMost popular movies (by interaction count):\")\n",
    "idx_to_movie = movie_mappings['idx_to_movie']\n",
    "for i, idx in enumerate(popular_movie_indices):\n",
    "    movie_name = idx_to_movie[idx]\n",
    "    count = int(movie_popularity[idx])\n",
    "    print(f\"{i+1:2d}. {movie_name} (interactions: {count})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "603f56b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Preparing Validation Data ===\n",
      "Validation segments: 56,723\n",
      "Validation interactions: 3,405\n",
      "Validation users: 3,392\n",
      "Validation movies: 2,338\n",
      "\n",
      "Validation split:\n",
      "Known users: 11,680 interactions\n",
      "New users (cold start): 45,043 interactions\n"
     ]
    }
   ],
   "source": [
    "# Load validation data\n",
    "print(\"=== Preparing Validation Data ===\")\n",
    "\n",
    "val_data = []\n",
    "with open('data/processed/val_watch_segments.jsonl', 'r') as f:\n",
    "    for line in f:\n",
    "        val_data.append(json.loads(line))\n",
    "\n",
    "print(f\"Validation segments: {len(val_data):,}\")\n",
    "\n",
    "# Process validation data\n",
    "val_users = []\n",
    "val_movies = []\n",
    "for segment in val_data:\n",
    "    user_id = segment['user_id']\n",
    "    movie_id = segment['movie_id']\n",
    "    val_users.append(user_id)\n",
    "    val_movies.append(movie_id)\n",
    "\n",
    "# Count unique interactions\n",
    "val_interactions = len(set(zip(val_users, val_movies)))\n",
    "print(f\"Validation interactions: {val_interactions:,}\")\n",
    "print(f\"Validation users: {len(set(val_users)):,}\")\n",
    "print(f\"Validation movies: {len(set(val_movies)):,}\")\n",
    "\n",
    "# Split validation data into known and new users\n",
    "known_users = []\n",
    "new_users = []\n",
    "user_to_idx = user_mappings['user_to_idx']\n",
    "movie_to_idx = movie_mappings['movie_to_idx']\n",
    "\n",
    "for user_id, movie_id in zip(val_users, val_movies):\n",
    "    if user_id in user_to_idx and movie_id in movie_to_idx:\n",
    "        known_users.append((user_id, movie_id))\n",
    "    else:\n",
    "        new_users.append((user_id, movie_id))\n",
    "\n",
    "print(f\"\\nValidation split:\")\n",
    "print(f\"Known users: {len(known_users):,} interactions\")\n",
    "print(f\"New users (cold start): {len(new_users):,} interactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66ca94ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Evaluation functions defined\n"
     ]
    }
   ],
   "source": [
    "# Define evaluation functions\n",
    "import time\n",
    "\n",
    "def evaluate_recommendations(recommendations, ground_truth, k=10):\n",
    "    \"\"\"Evaluate recommendation quality using precision, recall, and F1.\"\"\"\n",
    "    recommendations = recommendations[:k]\n",
    "    \n",
    "    if len(ground_truth) == 0:\n",
    "        return 0, 0, 0\n",
    "    \n",
    "    hits = len(set(recommendations) & set(ground_truth))\n",
    "    \n",
    "    precision = hits / len(recommendations) if recommendations else 0\n",
    "    recall = hits / len(ground_truth) if ground_truth else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "# Track inference times\n",
    "inference_times = []\n",
    "\n",
    "def get_als_recommendations(user_idx, model, train_matrix, n_items=10):\n",
    "    \"\"\"Get ALS recommendations for a user.\n",
    "    \n",
    "    Following the production code pattern from als_recommender.py\n",
    "    \"\"\"\n",
    "    # Get recommendations directly - model was trained on user-item matrix\n",
    "    # model.recommend returns (indices, scores) as two separate arrays\n",
    "    \n",
    "    # Record inference time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    recommended_indices, scores = model.recommend(\n",
    "        userid=user_idx,\n",
    "        user_items=train_matrix[user_idx],  # Pass the user's row\n",
    "        N=n_items,\n",
    "        filter_already_liked_items=True\n",
    "    )\n",
    "    \n",
    "    inference_time = time.time() - start_time\n",
    "    inference_times.append(inference_time)\n",
    "    \n",
    "    return recommended_indices  # Return just the indices\n",
    "\n",
    "print(\"âœ“ Evaluation functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd92678d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluating Model on Known Users ===\n",
      "\n",
      "âœ— User 47527: True=harry+potter+and+the+deathly+hallows+part+2+2011\n",
      "   Recommended: the+shawshank+redemption+1994, nausica+of+the+valley+of+the+wind+1984, star+wars+1977, 2001+a+space+odyssey+1968, scent+of+a+woman+1992\n",
      "\n",
      "âœ— User 83115: True=the+cobweb+1955\n",
      "   Recommended: the+shawshank+redemption+1994, 2001+a+space+odyssey+1968, nausica+of+the+valley+of+the+wind+1984, fight+club+1999, mickey_+donald_+goofy+the+three+musketeers+2004\n",
      "\n",
      "âœ— User 34100: True=sabotage+1936\n",
      "   Recommended: the+dark+knight+2008, aladdin+1992, snow+white+and+the+seven+dwarfs+1937, harry+potter+and+the+order+of+the+phoenix+2007, the+living+daylights+1987\n",
      "\n",
      "âœ— User 137263: True=i+bought+a+vampire+motorcycle+1990\n",
      "   Recommended: the+shawshank+redemption+1994, star+wars+1977, the+godfather+1972, monsters_+inc.+2001, inception+2010\n",
      "\n",
      "âœ— User 66688: True=black+and+white+in+color+1976\n",
      "   Recommended: winnie+the+pooh+and+the+honey+tree+1966, harry+potter+and+the+chamber+of+secrets+2002, busses+roar+1942, starship+troopers+1997, the+goebbels+experiment+2005\n",
      "\n",
      "Known Users Performance (N=10):\n",
      "- Average Precision: 0.0015\n",
      "- Average Recall: 0.0011\n",
      "- Average F1: 0.0012\n",
      "- Hit Rate: 0.0300\n",
      "- Evaluated on 100 users\n",
      "\n",
      "Inference Time Statistics:\n",
      "- Mean: 0.37 ms\n",
      "- Median: 0.30 ms\n",
      "- Min: 0.25 ms\n",
      "- Max: 3.41 ms\n",
      "- Total inference time: 0.037 seconds for 100 recommendations\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on known users\n",
    "print(\"=== Evaluating Model on Known Users ===\")\n",
    "\n",
    "# Reset inference times for this evaluation\n",
    "inference_times.clear()\n",
    "\n",
    "# Sample known users for evaluation\n",
    "known_user_interactions = {}\n",
    "for user_id, movie_id in known_users:\n",
    "    if user_id not in known_user_interactions:\n",
    "        known_user_interactions[user_id] = []\n",
    "    known_user_interactions[user_id].append(movie_id)\n",
    "\n",
    "# Evaluate a sample of known users\n",
    "sample_size = min(100, len(known_user_interactions))\n",
    "sample_users = list(known_user_interactions.keys())[:sample_size]\n",
    "\n",
    "known_precisions = []  # Changed variable name for clarity\n",
    "known_recalls = []\n",
    "known_f1_scores = []\n",
    "known_hit_rate = 0\n",
    "\n",
    "print_samples = 5\n",
    "samples_printed = 0\n",
    "\n",
    "for user_id in sample_users:\n",
    "    user_idx = user_to_idx[user_id]\n",
    "    \n",
    "    # Get recommendations (pass train_matrix as parameter)\n",
    "    rec_indices = get_als_recommendations(user_idx, model, train_matrix, n_items=20)\n",
    "    rec_movies = [idx_to_movie[idx] for idx in rec_indices]\n",
    "    \n",
    "    # Get ground truth\n",
    "    ground_truth = known_user_interactions[user_id]\n",
    "    \n",
    "    # Evaluate\n",
    "    precision, recall, f1 = evaluate_recommendations(rec_movies, ground_truth, k=20)\n",
    "    known_precisions.append(precision)\n",
    "    known_recalls.append(recall)\n",
    "    known_f1_scores.append(f1)\n",
    "    \n",
    "    if precision > 0:\n",
    "        known_hit_rate += 1\n",
    "    \n",
    "    # Print samples\n",
    "    if samples_printed < print_samples:\n",
    "        status = \"âœ“\" if precision > 0 else \"âœ—\"\n",
    "        print(f\"\\n{status} User {user_id}: True={ground_truth[0] if ground_truth else 'none'}\")\n",
    "        print(f\"   Recommended: {', '.join(rec_movies[:5])}\")\n",
    "        samples_printed += 1\n",
    "\n",
    "known_hit_rate = known_hit_rate / sample_size\n",
    "\n",
    "print(f\"\\nKnown Users Performance (N=10):\")\n",
    "print(f\"- Average Precision: {np.mean(known_precisions):.4f}\")\n",
    "print(f\"- Average Recall: {np.mean(known_recalls):.4f}\")\n",
    "print(f\"- Average F1: {np.mean(known_f1_scores):.4f}\")\n",
    "print(f\"- Hit Rate: {known_hit_rate:.4f}\")\n",
    "print(f\"- Evaluated on {sample_size} users\")\n",
    "\n",
    "# Report inference time statistics\n",
    "if inference_times:\n",
    "    print(f\"\\nInference Time Statistics:\")\n",
    "    print(f\"- Mean: {np.mean(inference_times)*1000:.2f} ms\")\n",
    "    print(f\"- Median: {np.median(inference_times)*1000:.2f} ms\")\n",
    "    print(f\"- Min: {np.min(inference_times)*1000:.2f} ms\")\n",
    "    print(f\"- Max: {np.max(inference_times)*1000:.2f} ms\")\n",
    "    print(f\"- Total inference time: {sum(inference_times):.3f} seconds for {len(inference_times)} recommendations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cae9a51f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Evaluating Cold Start Strategy ===\n",
      "Most popular recommendations for new users:\n",
      " 1. the+shawshank+redemption+1994\n",
      " 2. inception+2010\n",
      " 3. star+wars+1977\n",
      " 4. interstellar+2014\n",
      " 5. the+matrix+1999\n",
      " 6. spirited+away+2001\n",
      " 7. raiders+of+the+lost+ark+1981\n",
      " 8. blade+runner+1982\n",
      " 9. harry+potter+and+the+deathly+hallows+part+2+2011\n",
      "10. the+lord+of+the+rings+the+fellowship+of+the+ring+2001\n",
      "11. the+dark+knight+2008\n",
      "12. fight+club+1999\n",
      "13. the+lord+of+the+rings+the+two+towers+2002\n",
      "14. monsters_+inc.+2001\n",
      "15. forrest+gump+1994\n",
      "16. nausica+of+the+valley+of+the+wind+1984\n",
      "17. the+fifth+element+1997\n",
      "18. harry+potter+and+the+chamber+of+secrets+2002\n",
      "19. my+neighbor+totoro+1988\n",
      "20. whiplash+2014\n",
      "\n",
      "New Users Performance (Most Popular Strategy, N=10):\n",
      "- Average Precision: 0.0010\n",
      "- Average Recall: 0.0006\n",
      "- Average F1: 0.0008\n",
      "- Hit Rate: 0.0200\n",
      "- Evaluated on 50 users\n",
      "\n",
      "==================================================\n",
      "EVALUATION SUMMARY\n",
      "==================================================\n",
      "Known Users (ALS): Hit Rate = 0.0300, F1 = 0.0012\n",
      "New Users (Popular): Hit Rate = 0.0200, F1 = 0.0008\n",
      "Overall Hit Rate: 0.0250\n"
     ]
    }
   ],
   "source": [
    "# Evaluate cold start strategy (most popular items)\n",
    "print(\"=== Evaluating Cold Start Strategy ===\")\n",
    "\n",
    "# Get most popular movies for recommendations\n",
    "movie_popularity = np.array(train_matrix.sum(axis=0)).flatten()\n",
    "popular_movie_indices = np.argsort(-movie_popularity)[:20]\n",
    "popular_movies = [idx_to_movie[idx] for idx in popular_movie_indices]\n",
    "\n",
    "print(\"Most popular recommendations for new users:\")\n",
    "for i, movie in enumerate(popular_movies):\n",
    "    print(f\"{i+1:2d}. {movie}\")\n",
    "\n",
    "# Evaluate on new users\n",
    "new_user_interactions = {}\n",
    "for user_id, movie_id in new_users:\n",
    "    if user_id not in new_user_interactions:\n",
    "        new_user_interactions[user_id] = []\n",
    "    new_user_interactions[user_id].append(movie_id)\n",
    "\n",
    "# Sample new users for evaluation\n",
    "sample_size = min(50, len(new_user_interactions))\n",
    "sample_new_users = list(new_user_interactions.keys())[:sample_size]\n",
    "\n",
    "new_precisions = []\n",
    "new_recalls = []\n",
    "new_f1_scores = []\n",
    "new_hit_rate = 0\n",
    "\n",
    "for user_id in sample_new_users:\n",
    "    # Use popular movies as recommendations\n",
    "    rec_movies = popular_movies\n",
    "    \n",
    "    # Get ground truth\n",
    "    ground_truth = new_user_interactions[user_id]\n",
    "    \n",
    "    # Evaluate\n",
    "    precision, recall, f1 = evaluate_recommendations(rec_movies, ground_truth, k=20)\n",
    "    new_precisions.append(precision)\n",
    "    new_recalls.append(recall)\n",
    "    new_f1_scores.append(f1)\n",
    "    \n",
    "    if precision > 0:\n",
    "        new_hit_rate += 1\n",
    "\n",
    "new_hit_rate = new_hit_rate / sample_size\n",
    "\n",
    "print(f\"\\nNew Users Performance (Most Popular Strategy, N=10):\")\n",
    "print(f\"- Average Precision: {np.mean(new_precisions):.4f}\")\n",
    "print(f\"- Average Recall: {np.mean(new_recalls):.4f}\")\n",
    "print(f\"- Average F1: {np.mean(new_f1_scores):.4f}\")\n",
    "print(f\"- Hit Rate: {new_hit_rate:.4f}\")\n",
    "print(f\"- Evaluated on {sample_size} users\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EVALUATION SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Known Users (ALS): Hit Rate = {known_hit_rate:.4f}, F1 = {np.mean(known_f1_scores):.4f}\")\n",
    "print(f\"New Users (Popular): Hit Rate = {new_hit_rate:.4f}, F1 = {np.mean(new_f1_scores):.4f}\")\n",
    "print(f\"Overall Hit Rate: {(known_hit_rate + new_hit_rate) / 2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2bcb890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Recommendation System API ===\n",
      "âœ“ Recommendation System initialized\n"
     ]
    }
   ],
   "source": [
    "# Create a recommendation system class\n",
    "class ALSRecommendationSystem:\n",
    "    def __init__(self, model, train_matrix, user_mappings, movie_mappings, popular_movies):\n",
    "        self.model = model\n",
    "        self.train_matrix = train_matrix\n",
    "        self.user_to_idx = user_mappings['user_to_idx']\n",
    "        self.idx_to_user = user_mappings['idx_to_user']\n",
    "        self.movie_to_idx = movie_mappings['movie_to_idx']\n",
    "        self.idx_to_movie = movie_mappings['idx_to_movie']\n",
    "        self.popular_movies = popular_movies\n",
    "        \n",
    "    def recommend_for_user(self, user_id, n_recommendations=10):\n",
    "        \"\"\"Get recommendations for a user (handles cold start).\n",
    "        \n",
    "        Following the production code pattern from als_recommender.py\n",
    "        \"\"\"\n",
    "        if user_id in self.user_to_idx:\n",
    "            # Known user - use ALS\n",
    "            user_idx = self.user_to_idx[user_id]\n",
    "            \n",
    "            # Get recommendations (following production code lines 181-186)\n",
    "            # model.recommend returns (indices, scores) as two separate arrays\n",
    "            recommended_indices, scores = self.model.recommend(\n",
    "                userid=user_idx,\n",
    "                user_items=self.train_matrix[user_idx],\n",
    "                N=n_recommendations,\n",
    "                filter_already_liked_items=True\n",
    "            )\n",
    "            \n",
    "            # Combine indices and scores\n",
    "            recommendations = []\n",
    "            for idx, score in zip(recommended_indices, scores):\n",
    "                movie_id = self.idx_to_movie[idx]\n",
    "                recommendations.append((movie_id, float(score)))\n",
    "            \n",
    "            return {\n",
    "                'user_id': user_id,\n",
    "                'type': 'known, ALS',\n",
    "                'recommendations': recommendations\n",
    "            }\n",
    "        else:\n",
    "            # New user - return most popular\n",
    "            return {\n",
    "                'user_id': user_id,\n",
    "                'type': 'new, most_popular',\n",
    "                'recommendations': [(movie, None) for movie in self.popular_movies[:n_recommendations]]\n",
    "            }\n",
    "    \n",
    "    def find_similar_movies(self, movie_id, n_similar=10):\n",
    "        \"\"\"Find movies similar to a given movie.\"\"\"\n",
    "        if movie_id not in self.movie_to_idx:\n",
    "            return None\n",
    "        \n",
    "        movie_idx = self.movie_to_idx[movie_id]\n",
    "        # similar_items also returns (indices, scores) as two separate arrays\n",
    "        similar_indices, scores = self.model.similar_items(movie_idx, N=n_similar+1)\n",
    "        \n",
    "        # Skip the first result (the movie itself) and combine indices with scores\n",
    "        similar_movies = []\n",
    "        for idx, score in zip(similar_indices[1:], scores[1:]):\n",
    "            movie_name = self.idx_to_movie[idx]\n",
    "            similar_movies.append((movie_name, float(score)))\n",
    "        \n",
    "        return {\n",
    "            'movie_id': movie_id,\n",
    "            'similar_movies': similar_movies\n",
    "        }\n",
    "\n",
    "# Initialize the recommendation system\n",
    "recommender = ALSRecommendationSystem(\n",
    "    model=model,\n",
    "    train_matrix=train_matrix,\n",
    "    user_mappings=user_mappings,\n",
    "    movie_mappings=movie_mappings,\n",
    "    popular_movies=popular_movies\n",
    ")\n",
    "\n",
    "print(\"=== Recommendation System API ===\")\n",
    "print(\"âœ“ Recommendation System initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67e7fae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Recommendation System Demo ===\n",
      "1. Testing with known users:\n",
      "\n",
      "User: 100006 (new, most_popular)\n",
      "Recommendations:\n",
      "  1. the+shawshank+redemption+1994\n",
      "  2. inception+2010\n",
      "  3. star+wars+1977\n",
      "  4. interstellar+2014\n",
      "  5. the+matrix+1999\n",
      "\n",
      "User: 100013 (new, most_popular)\n",
      "Recommendations:\n",
      "  1. the+shawshank+redemption+1994\n",
      "  2. inception+2010\n",
      "  3. star+wars+1977\n",
      "  4. interstellar+2014\n",
      "  5. the+matrix+1999\n",
      "\n",
      "User: 10002 (new, most_popular)\n",
      "Recommendations:\n",
      "  1. the+shawshank+redemption+1994\n",
      "  2. inception+2010\n",
      "  3. star+wars+1977\n",
      "  4. interstellar+2014\n",
      "  5. the+matrix+1999\n",
      "\n",
      "2. Testing with new user:\n",
      "\n",
      "User: new_user_12345 (new, most_popular)\n",
      "Recommendations:\n",
      "  1. the+shawshank+redemption+1994 \n",
      "  2. inception+2010 \n",
      "  3. star+wars+1977 \n",
      "  4. interstellar+2014 \n",
      "  5. the+matrix+1999 \n",
      "\n",
      "3. Testing similar movies:\n",
      "\n",
      "Movies similar to: +nos+amours+1983\n",
      "  1. grand+canyon+1991 (similarity: 1.000)\n",
      "  2. why+we+fight+the+nazis+strike+1943 (similarity: 1.000)\n",
      "  3. the+tree+2010 (similarity: 1.000)\n",
      "  4. eagle+vs+shark+2007 (similarity: 1.000)\n",
      "  5. the+pokrovsky+gates+1982 (similarity: 1.000)\n",
      "\n",
      "==================================================\n",
      "ðŸŽ¬ ALS RECOMMENDATION SYSTEM READY!\n",
      "==================================================\n",
      "Features:\n",
      "âœ“ Personalized recommendations for known users (ALS)\n",
      "âœ“ Most popular recommendations for new users\n",
      "âœ“ Movie similarity search\n",
      "âœ“ Comprehensive evaluation metrics\n",
      "\n",
      "System Statistics:\n",
      "- Training users: 25,262\n",
      "- Training movies: 11,557\n",
      "- Model factors: 64\n",
      "- Training iterations: 20\n",
      "\n",
      "=== Saving Model ===\n",
      "âœ“ Model saved to: data/models/als_model.pkl\n",
      "Ready for production deployment!\n"
     ]
    }
   ],
   "source": [
    "# Demo the recommendation system\n",
    "print(\"=== Recommendation System Demo ===\")\n",
    "print(\"1. Testing with known users:\")\n",
    "\n",
    "# Test with some known users\n",
    "test_users = [100006, 100013, 10002]\n",
    "for user_id in test_users:\n",
    "    result = recommender.recommend_for_user(user_id, n_recommendations=5)\n",
    "    print(f\"\\nUser: {result['user_id']} ({result['type']})\")\n",
    "    print(\"Recommendations:\")\n",
    "    for i, (movie, score) in enumerate(result['recommendations'], 1):\n",
    "        if score:\n",
    "            print(f\"  {i}. {movie} (score: {score:.3f})\")\n",
    "        else:\n",
    "            print(f\"  {i}. {movie}\")\n",
    "\n",
    "# Test with a new user\n",
    "print(\"\\n2. Testing with new user:\")\n",
    "new_user_id = \"new_user_12345\"\n",
    "result = recommender.recommend_for_user(new_user_id, n_recommendations=5)\n",
    "print(f\"\\nUser: {result['user_id']} ({result['type']})\")\n",
    "print(\"Recommendations:\")\n",
    "for i, (movie, score) in enumerate(result['recommendations'], 1):\n",
    "    if score:\n",
    "        print(f\"  {i}. {movie} (score: {score:.3f})\")\n",
    "    else:\n",
    "        print(f\"  {i}. {movie} \")\n",
    "\n",
    "# Test movie similarity\n",
    "print(\"\\n3. Testing similar movies:\")\n",
    "test_movie = \"+nos+amours+1983\"\n",
    "similar_result = recommender.find_similar_movies(test_movie, n_similar=5)\n",
    "if similar_result:\n",
    "    print(f\"\\nMovies similar to: {similar_result['movie_id']}\")\n",
    "    for i, (movie, score) in enumerate(similar_result['similar_movies'], 1):\n",
    "        print(f\"  {i}. {movie} (similarity: {score:.3f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ðŸŽ¬ ALS RECOMMENDATION SYSTEM READY!\")\n",
    "print(\"=\"*50)\n",
    "print(\"Features:\")\n",
    "print(\"âœ“ Personalized recommendations for known users (ALS)\")\n",
    "print(\"âœ“ Most popular recommendations for new users\")\n",
    "print(\"âœ“ Movie similarity search\")\n",
    "print(\"âœ“ Comprehensive evaluation metrics\")\n",
    "print(f\"\\nSystem Statistics:\")\n",
    "print(f\"- Training users: {len(user_to_idx):,}\")\n",
    "print(f\"- Training movies: {len(movie_to_idx):,}\")\n",
    "print(f\"- Model factors: {factors}\")\n",
    "print(f\"- Training iterations: {iterations}\")\n",
    "\n",
    "# Save the model and recommendation system\n",
    "print(\"\\n=== Saving Model ===\")\n",
    "import os\n",
    "os.makedirs('data/models', exist_ok=True)\n",
    "\n",
    "# Save the complete recommendation system\n",
    "with open('data/models/als_model.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'model': model,\n",
    "        'train_matrix': train_matrix,\n",
    "        'user_mappings': user_mappings,\n",
    "        'movie_mappings': movie_mappings,\n",
    "        'popular_movies': popular_movies,\n",
    "        'hyperparameters': {\n",
    "            'factors': factors,\n",
    "            'iterations': iterations,\n",
    "            'regularization': regularization,\n",
    "            'alpha': alpha\n",
    "        }\n",
    "    }, f)\n",
    "\n",
    "print(\"âœ“ Model saved to: data/models/als_model.pkl\")\n",
    "print(\"Ready for production deployment!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a446c3eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
